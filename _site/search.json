[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "",
    "text": "This post presents a step-by-step process employed to model students’ knowledge using interaction log data. For the analysis, log data from an educational tool, named vara, have been used.\nVara is a sandbox platform built upon Drupal to facilitates the implementation of research ideas in the educational domain. This tool allows teachers/researchers to create H5P-based learning materials. Additionally, the tool records students’ interactions in the form of log data.\nThis post analyzes those interaction data in the context of new functionality added to the Vara, i.e., instructional trajectories. The instructional trajectory is a way to group learning materials and provide a structure among those groups of learning materials. Each subject is decomposed into groups known as Episodes which focus on a particular concept in the subject. Each episode is further decomposed into Activities which are then further divided into Tasks. Each task has a pre-specified skill(s) associated with it."
  },
  {
    "objectID": "index.html#exploring-log-dataset",
    "href": "index.html#exploring-log-dataset",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Exploring log dataset",
    "text": "Exploring log dataset\nThe goal is to generate open learner models using a log dataset of instructional trajectories. The log dataset contains students’ interaction with each task. More concretely, each interaction is recorded in the form of a set of attributes, e.g., time spent, number of attempts, score, number of times hints used, etc.\n\n\nCode\n# importing pandas library\nimport pandas as pd\n\n# loading log dataset\ndata = pd.read_csv('instructional-trajectory-session-24-results.csv')\n\ndata.head()\n\n\n\n\n\n\n\n\n\n\nStudent\nTime spent\nLast completed\nHarilik murd\nMeenutamine\nUsed supportive materials\n1. digitund_harilik murd_ASK1: meenutamine\nRequired\nTime spent in seconds\nNumber of retries\n...\nScore.103\nAnswer (left empty if library is not supported).103\n5. digitund_erinimeliste algebraliste murdude liitmine_elulise sisuga ülesanne_2\nRequired.104\nTime spent in seconds.104\nNumber of retries.104\nUsed tips.104\nSuccess.104\nScore.104\nAnswer (left empty if library is not supported).104\n\n\n\n\n0\nPiret Koppel\n49m 46s\nNaN\nE1\nA1\n0\nT1\nYes\nNaN\n0\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n1\nPeetri kooli kasutaja 56\n983h 30m\nNaN\nE1\nA1\n0\nT1\nYes\n228.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n2\nPeetri kooli kasutaja 57\n983h 31m 33s\nNaN\nE1\nA1\n0\nT1\nYes\n177.0\n1\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n3\nPeetri kooli kasutaja 58\n983h 28m 49s\nNaN\nE1\nA1\n0\nT1\nYes\n10.0\n5\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n4\nPeetri kooli kasutaja 59\n843h 35m 32s\nNaN\nE1\nA1\n0\nT1\nYes\n48.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n\n\n5 rows × 911 columns\n\n\n\n\nEach record in the dataset presents a particular student’s interaction with all the tasks in the instructional trajectory. There are several instances when students have not interacted with tasks. In those cases, missing values were recorded for interactions."
  },
  {
    "objectID": "index.html#preprocessing-data",
    "href": "index.html#preprocessing-data",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Preprocessing data",
    "text": "Preprocessing data\nAs the first step, we will transform the dataset from its current form to a form where each record represents a student’s interaction with a single task.\n\n\nCode\n# pre-processing codes\n\nlabels = {0:'required',1:'time',2:'attempts',3:'hints',4:'success',5:'score',6:'answer',7:'---'}\n\ndef extract_data(row_data):\n    \"\"\" This function process records from log data obtained from vara on instructional trajectories.\n    \n    Args:\n        row_data (dict): row record in dictionary format\n        \n    Returns:\n        records : a dictionary containing processed records\n    \n    \"\"\"\n    current_episode = ''\n    current_activity = ''\n    current_task = ''\n\n    records = {}\n    \n    for item in row_data:\n        current_record = {}\n        \n        item = str(item)\n        if 'E' in item and 'H5P' not in item:\n            current_episode = item\n        \n        elif 'A' in item and 'H5P' not in item:\n            current_activity = item\n        \n        elif 'T' in item and 'H5P' not in item:\n            current_task = item\n            start = 0\n\n        elif 'H5P' in item or 'library' in item or ':' in item:\n            continue\n        else:\n            if current_episode == '' or current_activity == '' or current_task == '':\n                continue\n            else:\n                if not start &gt;6:\n                    records[f'{current_episode}_{current_activity}_{current_task}_{labels[start]}']  = item\n                start += 1\n                \n    save_records = {} \n    processed_record = records\n    \n    for key, value in processed_record.items():\n        parts = key.split('_')\n        \n        heirarchy = '_'.join(parts[:3])\n        if heirarchy not in save_records.keys():\n            save_records[heirarchy] = {}\n            \n        save_records[heirarchy][parts[3]] = value\n    return save_records\n\n\ndef get_df(data):\n    \"\"\"This function transforms current csv file into a pandas DataFrame.\n    The dataframe contains response to each task as a seperate entry.\n    \n    Args:\n        data (DataFrame): Pandas DataFrame of csv file of instructional trajectories logs\n        \n    Returns:\n        df (DataFrame): Processed dataframe\n    \n    \"\"\"\n\n    cols = ['student',\n             'task_heirarchy',\n             'required',\n             'time',\n             'attempts',\n             'hints',\n             'success',\n             'score']\n\n    # initialise the dataframe\n    df = pd.DataFrame(columns=cols)\n    \n    # iterate over each record in data\n    for index in data.index.to_list():\n        \n        # accessing current record in dict form\n        cur_record = data.iloc[index].to_dict()\n\n        # dict for processed record\n        save_record = {}\n\n        # studen information\n        save_record['student'] = cur_record['Student']\n\n        # convert each record into task-wise records\n        processed_records = extract_data(data.iloc[index])\n\n        # iterate for each task\n        for task, values in processed_records.items():\n            save_record['task_heirarchy'] = task\n\n            for val_key, val_val in values.items():\n                save_record[val_key] = val_val\n            \n            # save a record of students' response to each task seperately\n            df = pd.concat([df, pd.DataFrame([save_record])], ignore_index=True)\n            \n    return df\n\n\n\n\nCode\n# transforming the dataset\ndf = get_df(data)\n\n# converting object data types to numeric\ndf['time'] = pd.to_numeric(df['time'],errors='coerce')\ndf['hints'] = pd.to_numeric(df['hints'],errors='coerce')\ndf['attempts'] = pd.to_numeric(df['attempts'],errors='coerce')\n\n# removing hints because all the values are 0\n# removing answer \ndf_ = df.drop(['hints','answer'], axis=1)\n\ndf_.tail(10)\n\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\n\n\n\n\n2538\nPeetri kooli kasutaja 78\nE12_A1_T6\nNo\n343.0\n5\nYes\n4/4\n\n\n2539\nPeetri kooli kasutaja 78\nE12_A1_T7\nNo\nNaN\n0\nNo\nnan\n\n\n2540\nPeetri kooli kasutaja 78\nE12_A2_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2541\nPeetri kooli kasutaja 78\nE12_A2_T2\nYes\nNaN\n0\nNo\nnan\n\n\n2542\nPeetri kooli kasutaja 78\nE12_A2_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2543\nPeetri kooli kasutaja 78\nE12_A3_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2544\nPeetri kooli kasutaja 78\nE12_A3_T2\nNo\nNaN\n0\nNo\nnan\n\n\n2545\nPeetri kooli kasutaja 78\nE12_A3_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2546\nPeetri kooli kasutaja 78\nE12_A3_T4\nYes\nNaN\n0\nNo\nnan\n\n\n2547\nPeetri kooli kasutaja 78\nE12_A3_T5\nYes\nNaN\n0\nNo\nnan\n\n\n\n\n\n\n\n\nThe above dataset now contains transformed data. Each record (line) represents interaction with a single task. For example, the record number 2538 presents interaction-related information for a user (Peetri Kooli kasutaja 78) interacting with a task E12_A1_T6. The task contains information about Episode as well as Activity. For example, E12_A1_T6 represents a task T6 in Episode 12 Activity 1."
  },
  {
    "objectID": "index.html#assiging-skills-for-each-task",
    "href": "index.html#assiging-skills-for-each-task",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Assiging skills for each task",
    "text": "Assiging skills for each task\nNext, we will specify skills targeted by each task. Here, one or more than one skill can be associated with each task. In our current dataset, we don’t have that information.\nTherefore, to allow our exploration, we have added some dummy skills (e.g., A, B, C) to our processed dataset.\n\n\nCode\n# reading Peetri kooli kasutaja 78, Episode 11 data with dummy skills\nep_78_skills = pd.read_csv('ep_78_with_skills.csv')\n\ndef score_to_num(x):\n    \"\"\"\n    This function takes a string in the form n1/n2 and returns the result of dividing n1 by n2.\n    \"\"\"\n    if x is None:\n        return -1\n    else:\n        f = x.split('/')[0]\n        s = x.split('/')[1]\n        return float(f)/float(s)\n\n# transform each score into a number\nep_78_skills['score_'] =  ep_78_skills['score'].apply(score_to_num) \n\nep_78_skills.head()\n\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\nskill\nscore_\n\n\n\n\n0\nPeetri kooli kasutaja 78\nE11_A1_T1\nYes\n30.0\n4\nYes\n3/3\nA\n1.0\n\n\n1\nPeetri kooli kasutaja 78\nE11_A1_T1\nYes\n30.0\n4\nYes\n3/3\nB\n1.0\n\n\n2\nPeetri kooli kasutaja 78\nE11_A1_T2\nNo\n23.0\n5\nYes\n3/3\nB\n1.0\n\n\n3\nPeetri kooli kasutaja 78\nE11_A1_T3\nNo\n27.0\n2\nYes\n3/3\nA\n1.0\n\n\n4\nPeetri kooli kasutaja 78\nE11_A1_T3\nNo\n27.0\n2\nYes\n3/3\nC\n1.0\n\n\n\n\n\n\n\n\nThe above snapshot shows the current state of the dataset after adding skills and converting scores into numbers. Next, we will transform skill attribute into three different binary variables one for each skill.\n\n\nCode\n# generating binary variables for each skill\nep_78_skills_dummy = pd.get_dummies(ep_78_skills['skill'])\n\n# concatenating dataframes\nfinal_ep_78 = pd.concat([ep_78_skills[['required','time','attempts','score_']],ep_78_skills_dummy],axis=1)\n\n# printing\nfinal_ep_78.head()\n\n\n\n\n\n\n\n\n\n\nrequired\ntime\nattempts\nscore_\nA\nB\nC\n\n\n\n\n0\nYes\n30.0\n4\n1.0\nTrue\nFalse\nFalse\n\n\n1\nYes\n30.0\n4\n1.0\nFalse\nTrue\nFalse\n\n\n2\nNo\n23.0\n5\n1.0\nFalse\nTrue\nFalse\n\n\n3\nNo\n27.0\n2\n1.0\nTrue\nFalse\nFalse\n\n\n4\nNo\n27.0\n2\n1.0\nFalse\nFalse\nTrue"
  },
  {
    "objectID": "index.html#creating-bayesian-network",
    "href": "index.html#creating-bayesian-network",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Creating Bayesian network",
    "text": "Creating Bayesian network\nNow, we will use our processed dataset and build a Bayesian network. There could be different goals here, e.g., learning network structure or dependence among skills and attributes; learning conditional probabilities of an already given network.\nOur focus is on the second case, i.e., learning conditional probabilities given a network structure. To do that we will assume some dummy relationship among skills and attributes (this structure could come from a domain expert as well for real-world cases).\nOur assumed structure is\nA -&gt; B -&gt; C\nA -&gt; C\nA -&gt; attempts\nattempts -&gt; score_\nThe above structure tells that skill C is dependent on skill B and A. Skill B is dependent on skill A. The number of attempts made by students for tasks of skill A is dependent on skill A. In simple terms, it means that a student proficient in skill A is likely to have a smaller number of attempts when answering tasks associated with skill A. The number of attempts has an impact on the score achieved. There could be more relationships, however, for our example, we are keeping it short.\n\n\n\n\n\n\nImportant\n\n\n\nWe are using attemps and score attributes for tasks associated with the skill A to make the example simple. These attributes along with others (e.g., hints) should be used for each skill for modeling purposes.\n\n\n\n\nCode\n# importing libraries\nfrom pgmpy.models import BayesianNetwork\nimport networkx as nx\nimport pylab as plt\n\n# building network structure\nmodel = BayesianNetwork([('A', 'B'),\n                         ('A', 'C'),\n                         ('B', 'C'),\n                         ('A','attempts'),\n                         ('attempts','score_'),\n                         ])\n\n# plotting the network\nnx_graph = nx.DiGraph(model.edges())\nnx.draw(nx_graph, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nOnce we have our network structure, we can learn the parameters using our dataset. \n\n\n\n\nCode\n# fitting the dataset\nmodel.fit(final_ep_78)\n\n# printing conditional probabilities\ncpds = model.get_cpds()\nfor cpd in cpds:\n    print(cpd)\n\n\n+----------+------+\n| A(False) | 0.75 |\n+----------+------+\n| A(True)  | 0.25 |\n+----------+------+\n+----------+--------------------+---------+\n| A        | A(False)           | A(True) |\n+----------+--------------------+---------+\n| B(False) | 0.4444444444444444 | 1.0     |\n+----------+--------------------+---------+\n| B(True)  | 0.5555555555555556 | 0.0     |\n+----------+--------------------+---------+\n+----------+----------+----------+----------+---------+\n| A        | A(False) | A(False) | A(True)  | A(True) |\n+----------+----------+----------+----------+---------+\n| B        | B(False) | B(True)  | B(False) | B(True) |\n+----------+----------+----------+----------+---------+\n| C(False) | 0.0      | 1.0      | 1.0      | 0.5     |\n+----------+----------+----------+----------+---------+\n| C(True)  | 1.0      | 0.0      | 0.0      | 0.5     |\n+----------+----------+----------+----------+---------+\n+-------------+--------------------+--------------------+\n| A           | A(False)           | A(True)            |\n+-------------+--------------------+--------------------+\n| attempts(2) | 0.2222222222222222 | 0.3333333333333333 |\n+-------------+--------------------+--------------------+\n| attempts(3) | 0.2222222222222222 | 0.0                |\n+-------------+--------------------+--------------------+\n| attempts(4) | 0.1111111111111111 | 0.3333333333333333 |\n+-------------+--------------------+--------------------+\n| attempts(5) | 0.4444444444444444 | 0.3333333333333333 |\n+-------------+--------------------+--------------------+\n+-------------+-------------+-------------+-------------+-------------+\n| attempts    | attempts(2) | attempts(3) | attempts(4) | attempts(5) |\n+-------------+-------------+-------------+-------------+-------------+\n| score_(1.0) | 1.0         | 1.0         | 1.0         | 1.0         |\n+-------------+-------------+-------------+-------------+-------------+\n\n\nAs a result of learning, we have now conditional probabilities for each of our nodes. These conditional probabilities can be used to visualize the Bayesian network in the following way.\n\n\n\nvis.png\n\n\nNote: In our exploration, we only used interaction data from Episode 11 and used only two attributes attemps and score for the skill A only. The goal was to demonstrate the process of student modeling using log data. These attributes can be utilized for other skills as well."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html",
    "href": "Plotting open learner model using trajectories data.html",
    "title": "Creating Bayesian Network",
    "section": "",
    "text": "Vara is a sandbox platform built upon Drupal to facilitates the implementation of research ideas in educational domain. This tool allows teachers/researchers to create H5P-based learning materials.\nThe tool also records students’ interactions. This notebook analyzes those interactions data in the context of a new functionality added to the Vara, i.e., instructional trajectories.\nThe task is to generate open learner model using trajectories’ data and domain model from VARA sandbox.\nWe have logs from students attempts of learning tasks grouped under activities which in turn combined into episodes."
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html#exploring-log-data",
    "href": "Plotting open learner model using trajectories data.html#exploring-log-data",
    "title": "Creating Bayesian Network",
    "section": "Exploring log data",
    "text": "Exploring log data\n\n# loading data\nimport pandas as pd\ndata = pd.read_csv('instructional-trajectory-session-24-results.csv')\n\nPython library to consider for bayesian analysis\n\nBayesPy\nPgmpy\nBnlearn\nPyBn\n\n\ndata.head()\n\n\n\n\n\n\n\n\n\nStudent\nTime spent\nLast completed\nHarilik murd\nMeenutamine\nUsed supportive materials\n1. digitund_harilik murd_ASK1: meenutamine\nRequired\nTime spent in seconds\nNumber of retries\n...\nScore.103\nAnswer (left empty if library is not supported).103\n5. digitund_erinimeliste algebraliste murdude liitmine_elulise sisuga ülesanne_2\nRequired.104\nTime spent in seconds.104\nNumber of retries.104\nUsed tips.104\nSuccess.104\nScore.104\nAnswer (left empty if library is not supported).104\n\n\n\n\n0\nPiret Koppel\n49m 46s\nNaN\nE1\nA1\n0\nT1\nYes\nNaN\n0\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n1\nPeetri kooli kasutaja 56\n983h 30m\nNaN\nE1\nA1\n0\nT1\nYes\n228.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n2\nPeetri kooli kasutaja 57\n983h 31m 33s\nNaN\nE1\nA1\n0\nT1\nYes\n177.0\n1\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n3\nPeetri kooli kasutaja 58\n983h 28m 49s\nNaN\nE1\nA1\n0\nT1\nYes\n10.0\n5\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n4\nPeetri kooli kasutaja 59\n843h 35m 32s\nNaN\nE1\nA1\n0\nT1\nYes\n48.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n\n\n5 rows × 911 columns\n\n\n\n\nThe dataset contains students’ interactions as well their response for all the tasks in a particularly chosen trajectories."
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html#preprocessing-data",
    "href": "Plotting open learner model using trajectories data.html#preprocessing-data",
    "title": "Creating Bayesian Network",
    "section": "Preprocessing data",
    "text": "Preprocessing data\nWe will convert data from current format to another format having each interaction of student as a seperate record.\n\nlabels = {0:'required',1:'time',2:'attempts',3:'hints',4:'success',5:'score',6:'answer',7:'---'}\n\n\ndef extract_data(row_data):\n    \"\"\" This function process records from log data obtained from vara on instructional trajectories.\n    \n    Args:\n        row_data (dict): row record in dictionary format\n        \n    Returns:\n        records : a dictionary containing processed records\n    \n    \"\"\"\n    current_episode = ''\n    current_activity = ''\n    current_task = ''\n\n    records = {}\n    \n    for item in row_data:\n        current_record = {}\n        \n        item = str(item)\n        if 'E' in item and 'H5P' not in item:\n            current_episode = item\n        \n        elif 'A' in item and 'H5P' not in item:\n            current_activity = item\n        \n        elif 'T' in item and 'H5P' not in item:\n            current_task = item\n            start = 0\n\n        elif 'H5P' in item or 'library' in item or ':' in item:\n            continue\n        else:\n            if current_episode == '' or current_activity == '' or current_task == '':\n                continue\n            else:\n                if not start &gt;6:\n                    records[f'{current_episode}_{current_activity}_{current_task}_{labels[start]}']  = item\n                start += 1\n                \n    save_records = {} \n    processed_record = records\n    \n    for key, value in processed_record.items():\n        parts = key.split('_')\n        \n        heirarchy = '_'.join(parts[:3])\n        if heirarchy not in save_records.keys():\n            save_records[heirarchy] = {}\n            \n        save_records[heirarchy][parts[3]] = value\n    return save_records\n\n\ndef get_df(data):\n    \"\"\"This function transforms current csv file into a pandas DataFrame.\n    The dataframe contains response to each task as a seperate entry.\n    \n    Args:\n        data (DataFrame): Pandas DataFrame of csv file of instructional trajectories logs\n        \n    Returns:\n        df (DataFrame): Processed dataframe\n    \n    \"\"\"\n\n    cols = ['student',\n             'task_heirarchy',\n             'required',\n             'time',\n             'attempts',\n             'hints',\n             'success',\n             'score']\n\n    # initialise the dataframe\n    df = pd.DataFrame(columns=cols)\n    \n    # iterate over each record in data\n    for index in data.index.to_list():\n        \n        # accessing current record in dict form\n        cur_record = data.iloc[index].to_dict()\n\n        # dict for processed record\n        save_record = {}\n\n        # studen information\n        save_record['student'] = cur_record['Student']\n\n        # convert each record into task-wise records\n        processed_records = extract_data(data.iloc[index])\n\n        # iterate for each task\n        for task, values in processed_records.items():\n            save_record['task_heirarchy'] = task\n\n            for val_key, val_val in values.items():\n                save_record[val_key] = val_val\n            \n            # save a record of students' response to each task seperately\n            df = pd.concat([df, pd.DataFrame([save_record])], ignore_index=True)\n            \n    return df\n\n\ndf['hints'].unique()\n\narray(['0'], dtype=object)\n\n\n\ndf = get_df(data)\n\n\ndf['time'] = pd.to_numeric(df['time'],errors='coerce')\ndf['hints'] = pd.to_numeric(df['hints'],errors='coerce')\ndf['attempts'] = pd.to_numeric(df['attempts'],errors='coerce')\n\ndf_ = df.drop(['hints','answer'], axis=1)\ndf_.tail(30)\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\n\n\n\n\n2518\nPeetri kooli kasutaja 78\nE10_A1_T4\nNo\n77.0\n1\nYes\n6/6\n\n\n2519\nPeetri kooli kasutaja 78\nE10_A1_T5\nYes\n8.0\n1\nYes\n4/4\n\n\n2520\nPeetri kooli kasutaja 78\nE10_A1_T6\nNo\n7.0\n2\nYes\n4/4\n\n\n2521\nPeetri kooli kasutaja 78\nE10_A1_T7\nNo\n19.0\n3\nYes\n4/4\n\n\n2522\nPeetri kooli kasutaja 78\nE10_A1_T8\nYes\n156.0\n2\nYes\n4/4\n\n\n2523\nPeetri kooli kasutaja 78\nE10_A1_T9\nNo\n124.0\n1\nYes\n4/4\n\n\n2524\nPeetri kooli kasutaja 78\nE10_A1_T10\nNo\n126.0\n7\nYes\n4/4\n\n\n2525\nPeetri kooli kasutaja 78\nE10_A1_T11\nYes\n121.0\n5\nYes\n6/6\n\n\n2526\nPeetri kooli kasutaja 78\nE11_A1_T1\nYes\n30.0\n4\nYes\n3/3\n\n\n2527\nPeetri kooli kasutaja 78\nE11_A1_T2\nNo\n23.0\n5\nYes\n3/3\n\n\n2528\nPeetri kooli kasutaja 78\nE11_A1_T3\nNo\n27.0\n2\nYes\n3/3\n\n\n2529\nPeetri kooli kasutaja 78\nE11_A2_T1\nYes\n73.0\n2\nYes\n3/3\n\n\n2530\nPeetri kooli kasutaja 78\nE11_A2_T2\nNo\n80.0\n5\nYes\n4/4\n\n\n2531\nPeetri kooli kasutaja 78\nE11_A2_T3\nNo\n67.0\n5\nYes\n4/4\n\n\n2532\nPeetri kooli kasutaja 78\nE11_A2_T4\nYes\n229.0\n3\nYes\n8/8\n\n\n2533\nPeetri kooli kasutaja 78\nE12_A1_T1\nYes\n286.0\n3\nYes\n8/8\n\n\n2534\nPeetri kooli kasutaja 78\nE12_A1_T2\nYes\n236.0\n7\nYes\n4/4\n\n\n2535\nPeetri kooli kasutaja 78\nE12_A1_T3\nNo\n466.0\n6\nYes\n4/4\n\n\n2536\nPeetri kooli kasutaja 78\nE12_A1_T4\nNo\n649.0\n17\nYes\n4/4\n\n\n2537\nPeetri kooli kasutaja 78\nE12_A1_T5\nYes\n180.0\n1\nYes\n4/4\n\n\n2538\nPeetri kooli kasutaja 78\nE12_A1_T6\nNo\n343.0\n5\nYes\n4/4\n\n\n2539\nPeetri kooli kasutaja 78\nE12_A1_T7\nNo\nNaN\n0\nNo\nnan\n\n\n2540\nPeetri kooli kasutaja 78\nE12_A2_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2541\nPeetri kooli kasutaja 78\nE12_A2_T2\nYes\nNaN\n0\nNo\nnan\n\n\n2542\nPeetri kooli kasutaja 78\nE12_A2_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2543\nPeetri kooli kasutaja 78\nE12_A3_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2544\nPeetri kooli kasutaja 78\nE12_A3_T2\nNo\nNaN\n0\nNo\nnan\n\n\n2545\nPeetri kooli kasutaja 78\nE12_A3_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2546\nPeetri kooli kasutaja 78\nE12_A3_T4\nYes\nNaN\n0\nNo\nnan\n\n\n2547\nPeetri kooli kasutaja 78\nE12_A3_T5\nYes\nNaN\n0\nNo\nnan\n\n\n\n\n\n\n\n\n\n## Analyzing data for episode 11\n\n# df for episode 11\nep_df = df_.loc[df_['task_heirarchy'].str.contains('E11'),:]\n\n\n# df for student Peetri kooli kasutaja 78\nep_78 = ep_df.loc[ep_df['student'] == 'Peetri kooli kasutaja 78',:]\n\n\nep_78.to_csv('ep_78.csv', index=False)\n\n\nep_78_skills = pd.read_csv('ep_78_with_skills.csv')\n\n\ndef score_to_num(x):\n    if x is None:\n        return -1\n    else:\n        f = x.split('/')[0]\n        s = x.split('/')[1]\n        return float(f)/float(s)\n\nep_78_skills['score_'] =  ep_78_skills['score'].apply(score_to_num) \n\n\nep_78_skills_dummy = pd.get_dummies(ep_78_skills['skill'])\n\n\nfinal_ep_78 = pd.concat([ep_78_skills[['required','time','attempts','score_']],ep_78_skills_dummy],axis=1)\n\n\nfinal_ep_78\n\n\n\n\n\n\n\n\n\nrequired\ntime\nattempts\nscore_\nA\nB\nC\n\n\n\n\n0\nYes\n30.0\n4\n1.0\nTrue\nFalse\nFalse\n\n\n1\nYes\n30.0\n4\n1.0\nFalse\nTrue\nFalse\n\n\n2\nNo\n23.0\n5\n1.0\nFalse\nTrue\nFalse\n\n\n3\nNo\n27.0\n2\n1.0\nTrue\nFalse\nFalse\n\n\n4\nNo\n27.0\n2\n1.0\nFalse\nFalse\nTrue\n\n\n5\nYes\n73.0\n2\n1.0\nFalse\nFalse\nTrue\n\n\n6\nNo\n80.0\n5\n1.0\nTrue\nFalse\nFalse\n\n\n7\nNo\n80.0\n5\n1.0\nFalse\nTrue\nFalse\n\n\n8\nNo\n80.0\n5\n1.0\nFalse\nFalse\nTrue\n\n\n9\nNo\n67.0\n5\n1.0\nFalse\nTrue\nFalse\n\n\n10\nYes\n229.0\n3\n1.0\nFalse\nTrue\nFalse\n\n\n11\nYes\n229.0\n3\n1.0\nFalse\nFalse\nTrue"
  }
]
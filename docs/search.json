[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "",
    "text": "This post presents a step-by-step process employed to model students’ knowledge using interaction log data. For the analysis, log data from an educational tool, named vara, have been used.\nVara is a sandbox platform built upon Drupal to facilitates the implementation of research ideas in the educational domain. This tool allows teachers/researchers to create H5P-based learning materials. Additionally, the tool records students’ interactions in the form of log data.\nThis post analyzes those interaction data in the context of new functionality added to the Vara, i.e., instructional trajectories. The instructional trajectory is a way to group learning materials and provide a structure among those groups of learning materials. Each subject is decomposed into groups known as Episodes which focus on a particular concept in the subject. Each episode is further decomposed into Activities which are then further divided into Tasks. Each task has a pre-specified skill(s) associated with it."
  },
  {
    "objectID": "index.html#exploring-log-dataset",
    "href": "index.html#exploring-log-dataset",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Exploring log dataset",
    "text": "Exploring log dataset\nThe goal is to generate open learner models using a log dataset of instructional trajectories. The log dataset contains students’ interaction with each task. More concretely, each interaction is recorded in the form of a set of attributes, e.g., time spent, number of attempts, score, number of times hints used, etc.\n\n\nCode\n# importing pandas library\nimport pandas as pd\n\n# loading log dataset\ndata = pd.read_csv('instructional-trajectory-session-24-results.csv')\n\ndata.head()\n\n\n\n\n\n\n\n\n\n\nStudent\nTime spent\nLast completed\nHarilik murd\nMeenutamine\nUsed supportive materials\n1. digitund_harilik murd_ASK1: meenutamine\nRequired\nTime spent in seconds\nNumber of retries\n...\nScore.103\nAnswer (left empty if library is not supported).103\n5. digitund_erinimeliste algebraliste murdude liitmine_elulise sisuga ülesanne_2\nRequired.104\nTime spent in seconds.104\nNumber of retries.104\nUsed tips.104\nSuccess.104\nScore.104\nAnswer (left empty if library is not supported).104\n\n\n\n\n0\nPiret Koppel\n49m 46s\nNaN\nE1\nA1\n0\nT1\nYes\nNaN\n0\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n1\nPeetri kooli kasutaja 56\n983h 30m\nNaN\nE1\nA1\n0\nT1\nYes\n228.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n2\nPeetri kooli kasutaja 57\n983h 31m 33s\nNaN\nE1\nA1\n0\nT1\nYes\n177.0\n1\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n3\nPeetri kooli kasutaja 58\n983h 28m 49s\nNaN\nE1\nA1\n0\nT1\nYes\n10.0\n5\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n4\nPeetri kooli kasutaja 59\n843h 35m 32s\nNaN\nE1\nA1\n0\nT1\nYes\n48.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n\n\n5 rows × 911 columns\n\n\n\n\nEach record in the dataset presents a particular student’s interaction with all the tasks in the instructional trajectory. There are several instances when students have not interacted with tasks. In those cases, missing values were recorded for interactions."
  },
  {
    "objectID": "index.html#preprocessing-data",
    "href": "index.html#preprocessing-data",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Preprocessing data",
    "text": "Preprocessing data\nAs the first step, we will transform the dataset from its current form to a form where each record represents a student’s interaction with a single task.\n\n\nCode\n# pre-processing codes\n\nlabels = {0:'required',1:'time',2:'attempts',3:'hints',4:'success',5:'score',6:'answer',7:'---'}\n\ndef extract_data(row_data):\n    \"\"\" This function process records from log data obtained from vara on instructional trajectories.\n    \n    Args:\n        row_data (dict): row record in dictionary format\n        \n    Returns:\n        records : a dictionary containing processed records\n    \n    \"\"\"\n    current_episode = ''\n    current_activity = ''\n    current_task = ''\n\n    records = {}\n    \n    for item in row_data:\n        current_record = {}\n        \n        item = str(item)\n        if 'E' in item and 'H5P' not in item:\n            current_episode = item\n        \n        elif 'A' in item and 'H5P' not in item:\n            current_activity = item\n        \n        elif 'T' in item and 'H5P' not in item:\n            current_task = item\n            start = 0\n\n        elif 'H5P' in item or 'library' in item or ':' in item:\n            continue\n        else:\n            if current_episode == '' or current_activity == '' or current_task == '':\n                continue\n            else:\n                if not start &gt;6:\n                    records[f'{current_episode}_{current_activity}_{current_task}_{labels[start]}']  = item\n                start += 1\n                \n    save_records = {} \n    processed_record = records\n    \n    for key, value in processed_record.items():\n        parts = key.split('_')\n        \n        heirarchy = '_'.join(parts[:3])\n        if heirarchy not in save_records.keys():\n            save_records[heirarchy] = {}\n            \n        save_records[heirarchy][parts[3]] = value\n    return save_records\n\n\ndef get_df(data):\n    \"\"\"This function transforms current csv file into a pandas DataFrame.\n    The dataframe contains response to each task as a seperate entry.\n    \n    Args:\n        data (DataFrame): Pandas DataFrame of csv file of instructional trajectories logs\n        \n    Returns:\n        df (DataFrame): Processed dataframe\n    \n    \"\"\"\n\n    cols = ['student',\n             'task_heirarchy',\n             'required',\n             'time',\n             'attempts',\n             'hints',\n             'success',\n             'score']\n\n    # initialise the dataframe\n    df = pd.DataFrame(columns=cols)\n    \n    # iterate over each record in data\n    for index in data.index.to_list():\n        \n        # accessing current record in dict form\n        cur_record = data.iloc[index].to_dict()\n\n        # dict for processed record\n        save_record = {}\n\n        # studen information\n        save_record['student'] = cur_record['Student']\n\n        # convert each record into task-wise records\n        processed_records = extract_data(data.iloc[index])\n\n        # iterate for each task\n        for task, values in processed_records.items():\n            save_record['task_heirarchy'] = task\n\n            for val_key, val_val in values.items():\n                save_record[val_key] = val_val\n            \n            # save a record of students' response to each task seperately\n            df = pd.concat([df, pd.DataFrame([save_record])], ignore_index=True)\n            \n    return df\n\n\n\n\nCode\n# transforming the dataset\ndf = get_df(data)\n\n# converting object data types to numeric\ndf['time'] = pd.to_numeric(df['time'],errors='coerce')\ndf['hints'] = pd.to_numeric(df['hints'],errors='coerce')\ndf['attempts'] = pd.to_numeric(df['attempts'],errors='coerce')\n\n# removing hints because all the values are 0\n# removing answer \ndf_ = df.drop(['hints','answer'], axis=1)\n\ndf_.tail(10)\n\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\n\n\n\n\n2538\nPeetri kooli kasutaja 78\nE12_A1_T6\nNo\n343.0\n5\nYes\n4/4\n\n\n2539\nPeetri kooli kasutaja 78\nE12_A1_T7\nNo\nNaN\n0\nNo\nnan\n\n\n2540\nPeetri kooli kasutaja 78\nE12_A2_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2541\nPeetri kooli kasutaja 78\nE12_A2_T2\nYes\nNaN\n0\nNo\nnan\n\n\n2542\nPeetri kooli kasutaja 78\nE12_A2_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2543\nPeetri kooli kasutaja 78\nE12_A3_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2544\nPeetri kooli kasutaja 78\nE12_A3_T2\nNo\nNaN\n0\nNo\nnan\n\n\n2545\nPeetri kooli kasutaja 78\nE12_A3_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2546\nPeetri kooli kasutaja 78\nE12_A3_T4\nYes\nNaN\n0\nNo\nnan\n\n\n2547\nPeetri kooli kasutaja 78\nE12_A3_T5\nYes\nNaN\n0\nNo\nnan\n\n\n\n\n\n\n\n\nThe above dataset now contains transformed data. Each record (line) represents interaction with a single task. For example, the record number 2538 presents interaction-related information for a user (Peetri Kooli kasutaja 78) interacting with a task E12_A1_T6. The task contains information about Episode as well as Activity. For example, E12_A1_T6 represents a task T6 in Episode 12 Activity 1."
  },
  {
    "objectID": "index.html#assiging-skills-for-each-task",
    "href": "index.html#assiging-skills-for-each-task",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Assiging skills for each task",
    "text": "Assiging skills for each task\nNext, we will specify skills targeted by each task. Here, one or more than one skill can be associated with each task. In our current dataset, we don’t have that information.\nTherefore, to allow our exploration, we have added some dummy skills (e.g., A, B, C) to our processed dataset.\n\n\nCode\n# reading Peetri kooli kasutaja 78, Episode 11 data with dummy skills\nep_78_skills = pd.read_csv('ep_78_with_skills.csv')\n\ndef score_to_num(x):\n    \"\"\"\n    This function takes a string in the form n1/n2 and returns the result of dividing n1 by n2.\n    \"\"\"\n    if x is None:\n        return -1\n    else:\n        f = x.split('/')[0]\n        s = x.split('/')[1]\n        return float(f)/float(s)\n\n# transform each score into a number\nep_78_skills['score_'] =  ep_78_skills['score'].apply(score_to_num) \n\nep_78_skills.head()\n\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\nskill\nscore_\n\n\n\n\n0\nPeetri kooli kasutaja 78\nE11_A1_T1\nYes\n30.0\n4\nYes\n3/3\nA\n1.0\n\n\n1\nPeetri kooli kasutaja 78\nE11_A1_T1\nYes\n30.0\n4\nYes\n3/3\nB\n1.0\n\n\n2\nPeetri kooli kasutaja 78\nE11_A1_T2\nNo\n23.0\n5\nYes\n3/3\nB\n1.0\n\n\n3\nPeetri kooli kasutaja 78\nE11_A1_T3\nNo\n27.0\n2\nYes\n3/3\nA\n1.0\n\n\n4\nPeetri kooli kasutaja 78\nE11_A1_T3\nNo\n27.0\n2\nYes\n3/3\nC\n1.0\n\n\n\n\n\n\n\n\nThe above snapshot shows the current state of the dataset after adding skills and converting scores into numbers. Next, we will transform skill attribute into three different binary variables one for each skill.\n\n\nCode\n# generating binary variables for each skill\nep_78_skills_dummy = pd.get_dummies(ep_78_skills['skill'])\n\n# concatenating dataframes\nfinal_ep_78 = pd.concat([ep_78_skills[['required','time','attempts','score_']],ep_78_skills_dummy],axis=1)\n\n# printing\nfinal_ep_78.head()\n\n\n\n\n\n\n\n\n\n\nrequired\ntime\nattempts\nscore_\nA\nB\nC\n\n\n\n\n0\nYes\n30.0\n4\n1.0\nTrue\nFalse\nFalse\n\n\n1\nYes\n30.0\n4\n1.0\nFalse\nTrue\nFalse\n\n\n2\nNo\n23.0\n5\n1.0\nFalse\nTrue\nFalse\n\n\n3\nNo\n27.0\n2\n1.0\nTrue\nFalse\nFalse\n\n\n4\nNo\n27.0\n2\n1.0\nFalse\nFalse\nTrue"
  },
  {
    "objectID": "index.html#creating-bayesian-network",
    "href": "index.html#creating-bayesian-network",
    "title": "Student modeling using log data from instructional trajectories",
    "section": "Creating Bayesian network",
    "text": "Creating Bayesian network\nNow, we will use our processed dataset and build a Bayesian network. There could be different goals here, e.g., learning network structure or dependence among skills and attributes; learning conditional probabilities of an already given network.\nOur focus is on the second case, i.e., learning conditional probabilities given a network structure. To do that we will assume some dummy relationship among skills and attributes (this structure could come from a domain expert as well for real-world cases).\nOur assumed structure is\nA -&gt; B -&gt; C\nA -&gt; C\nA -&gt; attempts\nattempts -&gt; score_\nThe above structure tells that skill C is dependent on skill B and A. Skill B is dependent on skill A. The number of attempts made by students for tasks of skill A is dependent on skill A. In simple terms, it means that a student proficient in skill A is likely to have a smaller number of attempts when answering tasks associated with skill A. The number of attempts has an impact on the score achieved. There could be more relationships, however, for our example, we are keeping it short.\n\n\n\n\n\n\nImportant\n\n\n\nWe are using attemps and score attributes for tasks associated with the skill A to make the example simple. These attributes along with others (e.g., hints) should be used for each skill for modeling purposes.\n\n\n\n\nCode\n# importing libraries\nfrom pgmpy.models import BayesianNetwork\nimport networkx as nx\nimport pylab as plt\n\n# building network structure\nmodel = BayesianNetwork([('A', 'B'),\n                         ('A', 'C'),\n                         ('B', 'C'),\n                         ('A','attempts'),\n                         ('attempts','score_'),\n                         ])\n\n# plotting the network\nnx_graph = nx.DiGraph(model.edges())\nnx.draw(nx_graph, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nOnce we have our network structure, we can learn the parameters using our dataset. \n\n\n\n\nCode\n# fitting the dataset\nmodel.fit(final_ep_78)\n\n# printing conditional probabilities\ncpds = model.get_cpds()\nfor cpd in cpds:\n    print(cpd)\n\n\n+----------+------+\n| A(False) | 0.75 |\n+----------+------+\n| A(True)  | 0.25 |\n+----------+------+\n+----------+--------------------+---------+\n| A        | A(False)           | A(True) |\n+----------+--------------------+---------+\n| B(False) | 0.4444444444444444 | 1.0     |\n+----------+--------------------+---------+\n| B(True)  | 0.5555555555555556 | 0.0     |\n+----------+--------------------+---------+\n+----------+----------+----------+----------+---------+\n| A        | A(False) | A(False) | A(True)  | A(True) |\n+----------+----------+----------+----------+---------+\n| B        | B(False) | B(True)  | B(False) | B(True) |\n+----------+----------+----------+----------+---------+\n| C(False) | 0.0      | 1.0      | 1.0      | 0.5     |\n+----------+----------+----------+----------+---------+\n| C(True)  | 1.0      | 0.0      | 0.0      | 0.5     |\n+----------+----------+----------+----------+---------+\n+-------------+--------------------+--------------------+\n| A           | A(False)           | A(True)            |\n+-------------+--------------------+--------------------+\n| attempts(2) | 0.2222222222222222 | 0.3333333333333333 |\n+-------------+--------------------+--------------------+\n| attempts(3) | 0.2222222222222222 | 0.0                |\n+-------------+--------------------+--------------------+\n| attempts(4) | 0.1111111111111111 | 0.3333333333333333 |\n+-------------+--------------------+--------------------+\n| attempts(5) | 0.4444444444444444 | 0.3333333333333333 |\n+-------------+--------------------+--------------------+\n+-------------+-------------+-------------+-------------+-------------+\n| attempts    | attempts(2) | attempts(3) | attempts(4) | attempts(5) |\n+-------------+-------------+-------------+-------------+-------------+\n| score_(1.0) | 1.0         | 1.0         | 1.0         | 1.0         |\n+-------------+-------------+-------------+-------------+-------------+\n\n\nAs a result of learning, we have now conditional probabilities for each of our nodes. These conditional probabilities can be used to visualize the Bayesian network in the following way.\nThe visualization given below is generated by a JS library jsbayes-viz.\n\n\n\nvis.png\n\n\nNote: In our exploration, we only used interaction data from Episode 11 and used only two attributes attemps and score for the skill A only. The goal was to demonstrate the process of student modeling using log data. These attributes can be utilized for other skills as well."
  },
  {
    "objectID": "student_modeling.html",
    "href": "student_modeling.html",
    "title": "Building learner model using vara dataset",
    "section": "",
    "text": "This post is in continuation with the previous post which presented a preliminary idea on building open learner models using Bayesian networks. The last post used the vara dataset partly and analyzed that data with some synthetically generated skill-related data. This post extends that idea with the vara dataset and actual skill-related dataset."
  },
  {
    "objectID": "student_modeling.html#log-dataset",
    "href": "student_modeling.html#log-dataset",
    "title": "Building learner model using vara dataset",
    "section": "Log dataset",
    "text": "Log dataset\nWe have a dataset that captured students’ interactions with the Vara platform. This dataset contains information such as number of attempts taken by a student, whether the student answered correctly or not, etc. The dataset has such information for several tasks which are grouped into activities. A sample of the dataset is shown below.\n\n\nCode\nimport pandas as pd\nimport numpy as np\ndata = pd.read_csv('instructional-trajectory-session-24-results.csv')\ndata.head()\n\n\n\n\n\n\n\n\n\n\nStudent\nTime spent\nLast completed\nHarilik murd\nMeenutamine\nUsed supportive materials\n1. digitund_harilik murd_ASK1: meenutamine\nRequired\nTime spent in seconds\nNumber of retries\n...\nScore.103\nAnswer (left empty if library is not supported).103\n5. digitund_erinimeliste algebraliste murdude liitmine_elulise sisuga ülesanne_2\nRequired.104\nTime spent in seconds.104\nNumber of retries.104\nUsed tips.104\nSuccess.104\nScore.104\nAnswer (left empty if library is not supported).104\n\n\n\n\n0\nPiret Koppel\n49m 46s\nNaN\nE1\nA1\n0\nT1\nYes\nNaN\n0\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n1\nPeetri kooli kasutaja 56\n983h 30m\nNaN\nE1\nA1\n0\nT1\nYes\n228.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n2\nPeetri kooli kasutaja 57\n983h 31m 33s\nNaN\nE1\nA1\n0\nT1\nYes\n177.0\n1\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n3\nPeetri kooli kasutaja 58\n983h 28m 49s\nNaN\nE1\nA1\n0\nT1\nYes\n10.0\n5\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n4\nPeetri kooli kasutaja 59\n843h 35m 32s\nNaN\nE1\nA1\n0\nT1\nYes\n48.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n\n\n5 rows × 911 columns"
  },
  {
    "objectID": "student_modeling.html#skill-dataset",
    "href": "student_modeling.html#skill-dataset",
    "title": "Building learner model using vara dataset",
    "section": "Skill dataset",
    "text": "Skill dataset\nAdditionally, we have also mapping data for each task to one or more skills. For example, a task is associated with the skill understanding common fractions which is part of a high-level skill II 5) reducing and expanding common fractions; adding, subtracting, multiplying and dividing two common fractions.\n\n\nCode\nskills_df = pd.read_csv('task_skills.csv')\nskills_df.iloc[:,0:3].head()\n\n\n\n\n\n\n\n\n\n\ntask_heirarchy\nlearning_outcome\nLO part\n\n\n\n\n0\nE1_A1_T1\nII 5) reducing and expanding common fractions;...\nunderstanding common fractions\n\n\n1\nE1_A1_T2\nII 5) reducing and expanding common fractions;...\nunderstanding common fractions\n\n\n2\nE1_A2_T1\nII 5) reducing and expanding common fractions;...\nunderstanding common fractions\n\n\n3\nE1_A2_T2\nII 5) reducing and expanding common fractions;...\nunderstanding common fractions\n\n\n4\nE1_A2_T3\nII 5) reducing and expanding common fractions;...\nunderstanding common fractions\n\n\n\n\n\n\n\n\nAs the skills presented above have dependencies on other skills, we will use that knowledge while building knowledge network structure.\nThe Figure 1 presents that dependency structure among skills and it also breaks down skills at finer level. Please don’t feel overwhelmed by the amount of information presented in the figure. This is just to provide an example of a dependency structure. We will use only some part of the information from this figure (we will discuss it in detail later).\nAs an example, we can see that II 5) reducing and expanding common fractions; adding, subtracting, multiplying and dividing two common fractions has several skills and one of them is understanding common fractions which is a pre-requisite for another skill expanding and reducing common fractions.\n\n\n\n\n\n\nFigure 1: Skills structure"
  },
  {
    "objectID": "student_modeling.html#network-structure",
    "href": "student_modeling.html#network-structure",
    "title": "Building learner model using vara dataset",
    "section": "Network structure",
    "text": "Network structure\nAs the first step, we will build a network structure where we will specify nodes (or variables) and the relationship between those nodes. Figure 2 shows a part of our network structure. We can see that the skill expands and reduces common fractions requires the skill of understanding common fractions. Also, these skills influence the number of attempts and success on tasks associated with them. For example, task E1_A1_T1 is associated with understanding common fractions; a student with a strong hold on the skill is likely to respond to the task correctly with relatively a lesser number of attempts in comparison with another student with a weak understanding of that skill.\n\n\nCode\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom pyvis.network import Network\n\ng = nx.DiGraph()\n\ng.add_edges_from([('understanding common fractions','expands and reduces common fractions'),\n                  ('understanding common fractions','E1_A1_T1_attempts'),\n                  ('understanding common fractions','E1_A1_T1_success'),\n                  ('expands and reduces common fractions','E2_A1_T3_attempts'),\n                  ('expands and reduces common fractions','E2_A1_T3_success')])\n\nnx.draw(g, with_labels=True)\nplt.margins(x=0.4)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Partial structure of the network\n\n\n\n\n\n\n\nCode\n\nskills_df = pd.read_csv('task_skills.csv')\n\nlatent_variables = ['understanding common fractions',\n       'expands and reduces common fractions',\n       'understanding algebraic fractions',\n       'projecting operations of expanding and reducing common fractions',\n       'expands and reduces algebraic fractions',\n       'projecting operations of multiplication of common fractions',\n       'multiplies algebraic fractions', 'divides algerbaic fractions',\n       'adds and substracts of algebraic fractions',\n       'projecting operations of adding common fractions',\n        'II 5','III 4','III 5']\n\n\ndef get_task_skill(df, task):\n    \"\"\"\n        This function returns the learning outcome associated with the specified task.\n        \n        Args:\n            df (DataFrame) : Pandas DataFrame object of logs data\n            task (str)     : Task for which to return learning outcome\n            \n        Returns:\n            str: learning outcome\n    \n    \"\"\"\n    \n    return df.loc[df['task_heirarchy'] == task, 'learning_outcome'].values[0]\n\n\ndef print_full(cpd):\n    \"\"\"\n    Function to print full CPDs table.\n    \"\"\"\n    backup = TabularCPD._truncate_strtable\n    TabularCPD._truncate_strtable = lambda self, x: x\n    print(cpd)\n    TabularCPD._truncate_strtable = backup\n    \n\n# preparing edges for Bayesian network\nedges = []\nfor index in skills_df.index:\n    record = skills_df.iloc[index].values\n\n    task = record[0]\n    high_skill = record[1]\n    high_skill = high_skill.split(')')[0]\n    skill = record[2]\n    \n    task_attempts = f'{task}_attempts'\n    task_success = f'{task}_success'\n    \n    if task_attempts in cols_to_remove or task_attempts not in df.columns or task_success not in df.columns:\n        continue\n\n    edges.append((high_skill, skill))\n    edges.append((skill, task_attempts))\n    edges.append((skill, task_success))\n\n    edges.append((task_attempts, task_success))\n    \n# adding dependency from skill network\nedges_ = list(set(edges))\nedges_.append(('understanding common fractions','expands and reduces common fractions'))\nedges_.append(('II 5','III 4'))\nedges_.append(('II 5','III 5'))\nedges_.append(('III 4','III 5'))\n\nedges_.append(('understanding algebraic fractions','expands and reduces algebraic fractions'))\nedges_.append(('expands and reduces algebraic fractions', 'adds and substracts of algebraic fractions'))\nedges_.append(('adds and substracts of algebraic fractions','multiplies algebraic fractions'))\nedges_.append(('multiplies algebraic fractions','divides algerbaic fractions'))\nedges_.append(('projecting operations of expanding and reducing common fractions', 'projecting operations of multiplication of common fractions'))\nedges_.append(('projecting operations of multiplication of common fractions','projecting operations of adding common fractions'))\n\n\nLet’s have a look on the complete network. Figure 3 shows the complete structure of our network.\n\n\nCode\nnx_graph = nx.DiGraph()\nnx_graph.add_edges_from(edges_)\nnt = Network('800px', '1000px',notebook=True,directed =True,cdn_resources='in_line')\n# populates the nodes and edges data structures\nnt.from_nx(nx_graph)\nnt.show('nx.html')\n\n\nnx.html\n\n\n\n\n\n        \n        \n\n\nFigure 3: Complete network structure"
  },
  {
    "objectID": "student_modeling.html#estimating-probabilities-for-skills",
    "href": "student_modeling.html#estimating-probabilities-for-skills",
    "title": "Building learner model using vara dataset",
    "section": "Estimating probabilities for skills",
    "text": "Estimating probabilities for skills\nNow, we will use our network structure and apply an estimation algorithm, i.e., Expectation Maximization (EM). The EM algorithm could be used in cases when the network involves some latent variables (or variables for which data is not available) to learn their probabilities.\nThe following code applies the EM algorithm and learn probabilities. Some of those probabilities are shown below.\n\n\nCode\nfrom pgmpy.models import BayesianNetwork\nimport networkx as nx\nfrom pgmpy.estimators import ExpectationMaximization as EM\nfrom pgmpy.factors.discrete.CPD import TabularCPD\n\n# building bayesian network\nnew_G = BayesianNetwork(edges_, latents={'understanding common fractions',\n       'expands and reduces common fractions',\n       'understanding algebraic fractions',\n       'projecting operations of expanding and reducing common fractions',\n       'expands and reduces algebraic fractions',\n       'projecting operations of multiplication of common fractions',\n       'multiplies algebraic fractions', 'divides algerbaic fractions',\n       'adds and substracts of algebraic fractions',\n       'projecting operations of adding common fractions',\n        'II 5','III 4','III 5'})\n\n# initializing EM estimator\nestimator = EM(new_G, df_)\n\n# estimating parameters\nall_cpds = estimator.get_parameters(max_iter=2)\n\nprint_full(all_cpds[0])\n\n\n+-----------------------------------+--------------------------------------+--------------------------------------+\n| understanding algebraic fractions | understanding algebraic fractions(0) | understanding algebraic fractions(1) |\n+-----------------------------------+--------------------------------------+--------------------------------------+\n| E3_A3_T1_attempts(0.0)            | 0.5745202455693615                   | 0.35173965103039506                  |\n+-----------------------------------+--------------------------------------+--------------------------------------+\n| E3_A3_T1_attempts(1.0)            | 0.1720550077738612                   | 0.4050739890829306                   |\n+-----------------------------------+--------------------------------------+--------------------------------------+\n| E3_A3_T1_attempts(2.0)            | 0.2534247466567772                   | 0.2431863598866744                   |\n+-----------------------------------+--------------------------------------+--------------------------------------+"
  },
  {
    "objectID": "student_modeling.html#assigning-learned-probabilities-to-the-bayesian-network",
    "href": "student_modeling.html#assigning-learned-probabilities-to-the-bayesian-network",
    "title": "Building learner model using vara dataset",
    "section": "Assigning learned probabilities to the Bayesian network",
    "text": "Assigning learned probabilities to the Bayesian network\nAs we have probabilities learned from the log data using Expectation Maximization algorithm, we will use them to initialize our Bayesian network. Now, this network can be used for inference purposes.\n\n\nCode\nbayes = new_G\n\n# setting conditional probabilities\nfor cpd in all_cpds:\n    bayes.add_cpds(cpd)"
  },
  {
    "objectID": "student_modeling.html#performing-inference-using-the-network",
    "href": "student_modeling.html#performing-inference-using-the-network",
    "title": "Building learner model using vara dataset",
    "section": "Performing inference using the network",
    "text": "Performing inference using the network\nNow we will use our network to infer probabilities for different skills given a student’s interaction data with some tasks. For this illustration, we will use interaction data from all the tasks from the trajectory. This should be noted that partial interaction data can also be used. For example, interaction with a single task or activity.\n\nVisualizing the network with probabilities\nFor an intuitive interpretation of the resultant probabilities for skills, we will now plot the network with the probabilities updated according to the student’s interaction to the tasks.\nLet’s use interaction data of a particular student with id Peetri kooli kasutaja 56. We will first obtain the probabilities for different skills given the student’s interaction, and then we will plot the network with the obtained probabilities as the color of the nodes.\nFigure 4 and Figure 5 below show the networks for two different students.\n\n\nCode\nfrom pgmpy.inference import VariableElimination\ndf_student = df_.copy()\ndf_student.reset_index(inplace=True, drop=True)\n\n# fetching a student's record\n\ndef show_prob_for_student(id, bayes):\n    \"\"\"\n        This function prints probabilities for a particular student.\n        \n        Args:\n            id (int): index of student in the log dataset\n            bayes (BayesianNetwork): Bayesian network (from pgmpy)\n    \"\"\"\n    #print('Student ID:',data.iloc[id,0])\n    \n    # inititing inference engine\n    infer = VariableElimination(bayes)\n\n    # accessing student record\n    student_record = df_student.iloc[id].to_dict()\n\n    #removing task which were not added to the network\n    evidence = {}\n\n    for key, value in student_record.items():\n        if key in bayes.nodes():\n            evidence[key] = value\n        \n    # creating a network for student\n    student_graph = nx.DiGraph()\n    \n    edges = []\n    for index in skills_df.index:\n        record = skills_df.iloc[index].values\n\n        task = record[0]\n        high_skill = record[1]\n        high_skill = high_skill.split(')')[0]\n        skill = record[2]\n\n        edges.append((high_skill, skill))\n\n    # adding dependency from skill network\n    edges_ = list(set(edges))\n    edges_.append(('understanding common fractions','expands and reduces common fractions'))\n    edges_.append(('II 5','III 4'))\n    edges_.append(('II 5','III 5'))\n    edges_.append(('III 4','III 5'))\n\n    edges_.append(('understanding algebraic fractions','expands and reduces algebraic fractions'))\n    edges_.append(('expands and reduces algebraic fractions', 'adds and substracts of algebraic fractions'))\n    edges_.append(('adds and substracts of algebraic fractions','multiplies algebraic fractions'))\n    edges_.append(('multiplies algebraic fractions','divides algerbaic fractions'))\n    edges_.append(('projecting operations of expanding and reducing common fractions', 'projecting operations of multiplication of common fractions'))\n    edges_.append(('projecting operations of multiplication of common fractions','projecting operations of adding common fractions'))\n\n    # adding edges to the network\n    student_graph.add_edges_from(edges_)\n\n    alpha_map = []\n    \n    # performing inference\n    \n    # using proabilities as alpha values for node color\n    for skill in student_graph.nodes():  \n        prob = infer.query([skill], evidence=evidence)    \n        alpha_map.append(prob.values[1])\n        \n    plt.figure(figsize=(10,8))\n    pos = nx.fruchterman_reingold_layout(student_graph)\n    nx.draw_networkx_nodes(student_graph,pos,node_color='green',alpha=alpha_map)\n    nx.draw_networkx_labels(student_graph, pos, font_size=8)\n    nx.draw_networkx_edges(student_graph, pos, edgelist=edges_, arrows=True)\n    plt.margins(x=0.4)\n    plt.title(f'Network for {data.iloc[id,0]}')\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nCode\nshow_prob_for_student(2, bayes)\n\n\n\n\n\n\n\n\nFigure 4: Bayesian network for Kasutaja 57\n\n\n\n\n\n\n\nCode\nshow_prob_for_student(10, bayes)\n\n\n\n\n\n\n\n\nFigure 5: Bayesian network for Kasutaja 65\n\n\n\n\n\n\n\n\nFigure 1: Skills structure"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html",
    "href": "Plotting open learner model using trajectories data.html",
    "title": "Creating Bayesian Network",
    "section": "",
    "text": "Vara is a sandbox platform built upon Drupal to facilitates the implementation of research ideas in educational domain. This tool allows teachers/researchers to create H5P-based learning materials.\nThe tool also records students’ interactions. This notebook analyzes those interactions data in the context of a new functionality added to the Vara, i.e., instructional trajectories.\nThe task is to generate open learner model using trajectories’ data and domain model from VARA sandbox.\nWe have logs from students attempts of learning tasks grouped under activities which in turn combined into episodes.\nUnderstanding common fractions\nexpanding and reducing common fractions\nunderstand algebraic fractions\nexpanding and reducing algebraic function\nintro to expanding and reducing algebraic function\nbridging from multiplication of common fractions\nintro to multiplication of algebraic fractions\nmultiplication of algebraic fractions\ndivision of algebraic fractions\naddition of algebraic fractions\nintro to addition of algebraic fractions"
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html#exploring-log-data",
    "href": "Plotting open learner model using trajectories data.html#exploring-log-data",
    "title": "Creating Bayesian Network",
    "section": "Exploring log data",
    "text": "Exploring log data\n\n# loading data\nimport pandas as pd\ndata = pd.read_csv('instructional-trajectory-session-24-results.csv')\n\nPython library to consider for bayesian analysis\n\nBayesPy\nPgmpy\nBnlearn\nPyBn\nPyCID\nPyAgrum\n\n\ndata.head()\n\n\n\n\n\n\n\n\n\nStudent\nTime spent\nLast completed\nHarilik murd\nMeenutamine\nUsed supportive materials\n1. digitund_harilik murd_ASK1: meenutamine\nRequired\nTime spent in seconds\nNumber of retries\n...\nScore.103\nAnswer (left empty if library is not supported).103\n5. digitund_erinimeliste algebraliste murdude liitmine_elulise sisuga ülesanne_2\nRequired.104\nTime spent in seconds.104\nNumber of retries.104\nUsed tips.104\nSuccess.104\nScore.104\nAnswer (left empty if library is not supported).104\n\n\n\n\n0\nPiret Koppel\n49m 46s\nNaN\nE1\nA1\n0\nT1\nYes\nNaN\n0\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n1\nPeetri kooli kasutaja 56\n983h 30m\nNaN\nE1\nA1\n0\nT1\nYes\n228.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n2\nPeetri kooli kasutaja 57\n983h 31m 33s\nNaN\nE1\nA1\n0\nT1\nYes\n177.0\n1\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n3\nPeetri kooli kasutaja 58\n983h 28m 49s\nNaN\nE1\nA1\n0\nT1\nYes\n10.0\n5\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n4\nPeetri kooli kasutaja 59\n843h 35m 32s\nNaN\nE1\nA1\n0\nT1\nYes\n48.0\n2\n...\nNaN\nNaN\nT5\nYes\nNaN\n0\n0\nNo\nNaN\nNaN\n\n\n\n\n5 rows × 911 columns\n\n\n\n\nThe dataset contains students’ interactions as well their response for all the tasks in a particularly chosen trajectories."
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html#preprocessing-data",
    "href": "Plotting open learner model using trajectories data.html#preprocessing-data",
    "title": "Creating Bayesian Network",
    "section": "Preprocessing data",
    "text": "Preprocessing data\nWe will convert data from current format to another format having each interaction of student as a seperate record.\n\nlabels = {0:'required',1:'time',2:'attempts',3:'hints',4:'success',5:'score',6:'answer',7:'---'}\n\n\ndef extract_data(row_data):\n    \"\"\" This function process records from log data obtained from vara on instructional trajectories.\n    \n    Args:\n        row_data (dict): row record in dictionary format\n        \n    Returns:\n        records : a dictionary containing processed records\n    \n    \"\"\"\n    current_episode = ''\n    current_activity = ''\n    current_task = ''\n\n    records = {}\n    \n    \n    for item in row_data:\n        current_record = {}\n        \n        item = str(item)\n \n        if 'E' in item and 'H5P' not in item:\n            current_episode = item\n            current_activity = ''\n            current_task = ''\n        \n        elif 'A' in item and 'H5P' not in item:\n            current_activity = item\n            current_task=''\n        \n        elif 'T' in item and 'H5P' not in item:\n            current_task = item\n            start = 0\n\n        elif 'H5P' in item or 'library' in item or ':' in item:\n            continue\n        else:\n            if current_episode == '' or current_activity == '' or current_task == '':\n                continue\n            else:\n                if not start &gt;6:\n                    records[f'{current_episode}_{current_activity}_{current_task}_{labels[start]}']  = item\n                start += 1\n\n                \n    save_records = {} \n    processed_record = records\n    \n    for key, value in processed_record.items():\n        parts = key.split('_')\n        \n        heirarchy = '_'.join(parts[:3])\n        if heirarchy not in save_records.keys():\n            save_records[heirarchy] = {}\n            \n        save_records[heirarchy][parts[3]] = value\n    return save_records\n\n\nextract_data(data.iloc[1])\n\n{'E1_A1_T1': {'required': 'Yes',\n  'time': '228.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'No',\n  'score': '3/4'},\n 'E1_A1_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E1_A2_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E1_A2_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E1_A2_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E1_A3_T1': {'required': 'Yes',\n  'time': '20.0',\n  'attempts': '3',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3'},\n 'E1_A3_T2': {'required': 'No',\n  'time': '49.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3'},\n 'E1_A3_T3': {'required': 'No',\n  'time': '36.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3'},\n 'E2_A1_T1': {'required': 'Yes',\n  'time': '76.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '1/1'},\n 'E2_A2_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E2_A2_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E2_A2_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E2_A3_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E2_A3_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E2_A3_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E3_A1_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E3_A1_T2': {'required': 'Yes',\n  'time': '83.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '1/1'},\n 'E3_A1_T3': {'required': 'Yes',\n  'time': '899.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '17/17',\n  'answer': 'nan'},\n 'E3_A2_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E3_A2_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E3_A2_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E3_A3_T1': {'required': 'Yes',\n  'time': '53',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '2/2',\n  'answer': 'nan'},\n 'E3_A3_T2': {'required': 'No',\n  'time': '70.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '2/2',\n  'answer': 'nan'},\n 'E3_A3_T3': {'required': 'No',\n  'time': '67.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '2/2',\n  'answer': 'nan'},\n 'E4_A1_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E4_A1_T2': {'required': 'Yes',\n  'time': '2520.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'No',\n  'score': '19/20',\n  'answer': 'nan'},\n 'E5_A1_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A1_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A1_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A2_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A2_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A2_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A3_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A3_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E5_A3_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E6_A1_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E6_A1_T2': {'required': 'Yes',\n  'time': '509.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'No',\n  'score': '6/10',\n  'answer': 'nan'},\n 'E6_A1_T3': {'required': 'Yes',\n  'time': '21.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '1/1'},\n 'E6_A1_T4': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E7_A1_T1': {'required': 'Yes',\n  'time': '33.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3'},\n 'E7_A1_T2': {'required': 'Yes',\n  'time': '46.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4'},\n 'E7_A1_T3': {'required': 'Yes',\n  'time': '101.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4'},\n 'E7_A2_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E7_A2_T2': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E8_A1_T1': {'required': 'Yes',\n  'time': '36.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E8_A1_T2': {'required': 'Yes',\n  'time': '285.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '21/21',\n  'answer': 'nan'},\n 'E8_A1_T3': {'required': 'Yes',\n  'time': '248.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E8_A1_T4': {'required': 'No',\n  'time': '128.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E8_A1_T5': {'required': 'No',\n  'time': '150.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E8_A2_T1': {'required': 'Yes',\n  'time': '33.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'No',\n  'score': '1/3'},\n 'E8_A2_T2': {'required': 'Yes',\n  'time': '174.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '8/8',\n  'answer': 'nan'},\n 'E8_A2_T3': {'required': 'Yes',\n  'time': '430.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '6/6',\n  'answer': 'nan'},\n 'E8_A2_T4': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E8_A3_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E8_A3_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E8_A3_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A1_T1': {'required': 'Yes',\n  'time': '1908.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E9_A1_T2': {'required': 'Yes',\n  'time': '95.0',\n  'attempts': '3',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '5/5'},\n 'E9_A1_T3': {'required': 'No',\n  'time': '128.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '6/6'},\n 'E9_A1_T4': {'required': 'Yes',\n  'time': '172.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '9/9',\n  'answer': 'nan'},\n 'E9_A1_T5': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A1_T6': {'required': 'Yes',\n  'time': '100.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '6/6'},\n 'E9_A2_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A2_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A2_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T1': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T4': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T5': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T6': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E9_A3_T7': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E10_A1_T1': {'required': 'Yes',\n  'time': '20.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '1/1',\n  'answer': 'nan'},\n 'E10_A1_T2': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E10_A1_T3': {'required': 'Yes',\n  'time': '73.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '5/5'},\n 'E10_A1_T4': {'required': 'No',\n  'time': '153.0',\n  'attempts': '4',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '6/6'},\n 'E10_A1_T5': {'required': 'Yes',\n  'time': '111.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'No',\n  'score': '3/4'},\n 'E10_A1_T6': {'required': 'No',\n  'time': '45.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4'},\n 'E10_A1_T7': {'required': 'No',\n  'time': '29.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4'},\n 'E10_A1_T8': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E10_A1_T9': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E10_A1_T10': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E10_A1_T11': {'required': 'Yes',\n  'time': '199.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '6/6',\n  'answer': 'nan'},\n 'E11_A1_T1': {'required': 'Yes',\n  'time': '294.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E11_A1_T2': {'required': 'No',\n  'time': '133.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E11_A1_T3': {'required': 'No',\n  'time': '244.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E11_A2_T1': {'required': 'Yes',\n  'time': '256.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E11_A2_T2': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E11_A2_T3': {'required': 'No',\n  'time': '147.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E11_A2_T4': {'required': 'Yes',\n  'time': '1379.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '8/8',\n  'answer': 'nan'},\n 'E12_A1_T1': {'required': 'Yes',\n  'time': '98.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '8/8',\n  'answer': 'nan'},\n 'E12_A1_T2': {'required': 'Yes',\n  'time': '132.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A1_T3': {'required': 'No',\n  'time': '162.0',\n  'attempts': '4',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A1_T4': {'required': 'No',\n  'time': '209.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A1_T5': {'required': 'Yes',\n  'time': '581.0',\n  'attempts': '5',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A1_T6': {'required': 'No',\n  'time': '137.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A1_T7': {'required': 'No',\n  'time': '305.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E12_A2_T1': {'required': 'Yes',\n  'time': '131.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A2_T2': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E12_A2_T3': {'required': 'No',\n  'time': '127.0',\n  'attempts': '1',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '3/3',\n  'answer': 'nan'},\n 'E12_A3_T1': {'required': 'Yes',\n  'time': '62.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A3_T2': {'required': 'No',\n  'time': '186.0',\n  'attempts': '2',\n  'hints': '0',\n  'success': 'Yes',\n  'score': '4/4',\n  'answer': 'nan'},\n 'E12_A3_T3': {'required': 'No',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E12_A3_T4': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'},\n 'E12_A3_T5': {'required': 'Yes',\n  'time': 'nan',\n  'attempts': '0',\n  'hints': '0',\n  'success': 'No',\n  'score': 'nan',\n  'answer': 'nan'}}\n\n\n\ndef get_df(data):\n    \"\"\"This function transforms current csv file into a pandas DataFrame.\n    The dataframe contains response to each task as a seperate entry.\n    \n    Args:\n        data (DataFrame): Pandas DataFrame of csv file of instructional trajectories logs\n        \n    Returns:\n        df (DataFrame): Processed dataframe\n    \n    \"\"\"\n\n    cols = ['student',\n             'task_heirarchy',\n             'required',\n             'time',\n             'attempts',\n             'hints',\n             'success',\n             'score']\n\n    # initialise the dataframe\n    df = pd.DataFrame(columns=cols)\n    \n    # iterate over each record in data\n    for index in data.index.to_list():\n        \n        # accessing current record in dict form\n        cur_record = data.iloc[index].to_dict()\n\n        # dict for processed record\n        save_record = {}\n\n        # studen information\n        save_record['student'] = cur_record['Student']\n\n        # convert each record into task-wise records\n        processed_records = extract_data(data.iloc[index])\n\n        # iterate for each task\n        for task, values in processed_records.items():\n            save_record['task_heirarchy'] = task\n\n            for val_key, val_val in values.items():\n                save_record[val_key] = val_val\n            \n            # save a record of students' response to each task seperately\n            df = pd.concat([df, pd.DataFrame([save_record])], ignore_index=True)\n            \n    return df\n\n\ndf['hints'].unique()\n\narray(['0'], dtype=object)\n\n\n\ndf = get_df(data)\n\n\ndf['time'] = pd.to_numeric(df['time'],errors='coerce')\ndf['hints'] = pd.to_numeric(df['hints'],errors='coerce')\ndf['attempts'] = pd.to_numeric(df['attempts'],errors='coerce')\n\n# no student used hints, therefore, removing it\ndf_ = df.drop(['hints','answer'], axis=1)\ndf_.tail(106)\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\n\n\n\n\n2442\nPeetri kooli kasutaja 78\nE1_A1_T1\nYes\n15.0\n3\nNo\n0/4\n\n\n2443\nPeetri kooli kasutaja 78\nE1_A1_T2\nNo\nNaN\n0\nNo\nnan\n\n\n2444\nPeetri kooli kasutaja 78\nE1_A2_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2445\nPeetri kooli kasutaja 78\nE1_A2_T2\nNo\nNaN\n0\nNo\nnan\n\n\n2446\nPeetri kooli kasutaja 78\nE1_A2_T3\nNo\nNaN\n0\nNo\nnan\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2543\nPeetri kooli kasutaja 78\nE12_A3_T1\nYes\nNaN\n0\nNo\nnan\n\n\n2544\nPeetri kooli kasutaja 78\nE12_A3_T2\nNo\nNaN\n0\nNo\nnan\n\n\n2545\nPeetri kooli kasutaja 78\nE12_A3_T3\nNo\nNaN\n0\nNo\nnan\n\n\n2546\nPeetri kooli kasutaja 78\nE12_A3_T4\nYes\nNaN\n0\nNo\nnan\n\n\n2547\nPeetri kooli kasutaja 78\nE12_A3_T5\nYes\nNaN\n0\nNo\nnan\n\n\n\n\n106 rows × 7 columns"
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html#setting-learning-outcomes-for-each-task",
    "href": "Plotting open learner model using trajectories data.html#setting-learning-outcomes-for-each-task",
    "title": "Creating Bayesian Network",
    "section": "Setting learning outcomes for each task",
    "text": "Setting learning outcomes for each task\n\nskills_df = pd.read_csv('task_to_skill_mapping.csv')\n\ndef get_task_skill(df, task):\n    \"\"\"\n        This function returns the learning outcome associated with the specified task.\n        \n        Args:\n            df (DataFrame) : Pandas DataFrame object of logs data\n            task (str)     : Task for which to return learning outcome\n            \n        Returns:\n            str: learning outcome\n    \n    \"\"\"\n    \n    return df.loc[df['task_heirarchy'] == task, 'learning_outcome'].values[0]\n\n\nget_task_skill(skills_df, 'E1_A1_T1')\n\n'understanding common fractions'\n\n\n\ndf_['outcomes'] = ''\nfor task in df_['task_heirarchy'].unique():\n    skill = get_task_skill(skills_df, task)\n    df_.loc[df_['task_heirarchy'] == task,'outcomes'] = skill\n\n\ndf_\n\n\n\n\n\n\n\n\n\nstudent\ntask_heirarchy\nrequired\ntime\nattempts\nsuccess\nscore\noutcomes\n\n\n\n\n0\nPiret Koppel\nE1_A1_T1\nYes\nNaN\n0\nNo\nnan\nunderstanding common fractions\n\n\n1\nPiret Koppel\nE1_A1_T2\nNo\nNaN\n0\nNo\nnan\nunderstanding common fractions\n\n\n2\nPiret Koppel\nE1_A2_T1\nYes\nNaN\n0\nNo\nnan\nunderstanding common fractions\n\n\n3\nPiret Koppel\nE1_A2_T2\nNo\nNaN\n0\nNo\nnan\nunderstanding common fractions\n\n\n4\nPiret Koppel\nE1_A2_T3\nNo\nNaN\n0\nNo\nnan\nunderstanding common fractions\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2543\nPeetri kooli kasutaja 78\nE12_A3_T1\nYes\nNaN\n0\nNo\nnan\naddition of algebraic fractions\n\n\n2544\nPeetri kooli kasutaja 78\nE12_A3_T2\nNo\nNaN\n0\nNo\nnan\naddition of algebraic fractions\n\n\n2545\nPeetri kooli kasutaja 78\nE12_A3_T3\nNo\nNaN\n0\nNo\nnan\naddition of algebraic fractions\n\n\n2546\nPeetri kooli kasutaja 78\nE12_A3_T4\nYes\nNaN\n0\nNo\nnan\naddition of algebraic fractions\n\n\n2547\nPeetri kooli kasutaja 78\nE12_A3_T5\nYes\nNaN\n0\nNo\nnan\naddition of algebraic fractions\n\n\n\n\n2548 rows × 8 columns"
  },
  {
    "objectID": "Plotting open learner model using trajectories data.html#converting-attributes-values-into-categories",
    "href": "Plotting open learner model using trajectories data.html#converting-attributes-values-into-categories",
    "title": "Creating Bayesian Network",
    "section": "Converting attributes’ values into categories",
    "text": "Converting attributes’ values into categories\n\nfor task in df_['task_heirarchy'].unique():\n    tmp_ = df_.loc[df_['task_heirarchy'] == task, ['time']]\n    tmp_mean = tmp_['time'].median()\n    print(f'Task {task} Average time {tmp_mean}')\n\nTask E1_A1_T1 Average time 92.0\nTask E1_A1_T2 Average time nan\nTask E1_A2_T1 Average time 9.5\nTask E1_A2_T2 Average time 8.0\nTask E1_A2_T3 Average time 11.0\nTask E1_A3_T1 Average time 73.5\nTask E1_A3_T2 Average time 20.5\nTask E1_A3_T3 Average time 42.0\nTask E2_A1_T1 Average time 35.0\nTask E2_A2_T1 Average time 79.0\nTask E2_A2_T2 Average time nan\nTask E2_A2_T3 Average time nan\nTask E2_A3_T1 Average time 17.0\nTask E2_A3_T2 Average time 17.0\nTask E2_A3_T3 Average time 17.0\nTask E3_A1_T1 Average time nan\nTask E3_A1_T2 Average time 68.0\nTask E3_A1_T3 Average time 833.5\nTask E3_A2_T1 Average time 120.5\nTask E3_A2_T2 Average time 13.0\nTask E3_A2_T3 Average time nan\nTask E3_A3_T1 Average time 61.0\nTask E3_A3_T2 Average time 59.0\nTask E3_A3_T3 Average time 76.5\nTask E4_A1_T1 Average time nan\nTask E4_A1_T2 Average time 2520.0\nTask E5_A1_T1 Average time 198.0\nTask E5_A1_T2 Average time 43.5\nTask E5_A1_T3 Average time 97.0\nTask E5_A2_T1 Average time 220.0\nTask E5_A2_T2 Average time 77.0\nTask E5_A2_T3 Average time 90.0\nTask E5_A3_T1 Average time nan\nTask E5_A3_T2 Average time nan\nTask E5_A3_T3 Average time nan\nTask E6_A1_T1 Average time 540.0\nTask E6_A1_T2 Average time 298.5\nTask E6_A1_T3 Average time 20.0\nTask E6_A1_T4 Average time 185.0\nTask E7_A1_T1 Average time 43.0\nTask E7_A1_T2 Average time 55.0\nTask E7_A1_T3 Average time 128.0\nTask E7_A2_T1 Average time 70.0\nTask E7_A2_T2 Average time 281.5\nTask E8_A1_T1 Average time 10.0\nTask E8_A1_T2 Average time 408.0\nTask E8_A1_T3 Average time 248.0\nTask E8_A1_T4 Average time 206.5\nTask E8_A1_T5 Average time 390.0\nTask E8_A2_T1 Average time 10.0\nTask E8_A2_T2 Average time 174.0\nTask E8_A2_T3 Average time 381.5\nTask E8_A2_T4 Average time 179.0\nTask E8_A3_T1 Average time 268.0\nTask E8_A3_T2 Average time 369.0\nTask E8_A3_T3 Average time 164.0\nTask E9_A1_T1 Average time 131.0\nTask E9_A1_T2 Average time 41.0\nTask E9_A1_T3 Average time 128.0\nTask E9_A1_T4 Average time 132.0\nTask E9_A1_T5 Average time nan\nTask E9_A1_T6 Average time 100.0\nTask E9_A2_T1 Average time 271.0\nTask E9_A2_T2 Average time nan\nTask E9_A2_T3 Average time nan\nTask E9_A3_T1 Average time nan\nTask E9_A3_T2 Average time nan\nTask E9_A3_T3 Average time nan\nTask E9_A3_T4 Average time nan\nTask E9_A3_T5 Average time nan\nTask E9_A3_T6 Average time nan\nTask E9_A3_T7 Average time nan\nTask E10_A1_T1 Average time 13.0\nTask E10_A1_T2 Average time 734.0\nTask E10_A1_T3 Average time 73.0\nTask E10_A1_T4 Average time 55.0\nTask E10_A1_T5 Average time 96.0\nTask E10_A1_T6 Average time 46.5\nTask E10_A1_T7 Average time 37.0\nTask E10_A1_T8 Average time 90.5\nTask E10_A1_T9 Average time 62.0\nTask E10_A1_T10 Average time 65.0\nTask E10_A1_T11 Average time 126.0\nTask E11_A1_T1 Average time 147.0\nTask E11_A1_T2 Average time 123.0\nTask E11_A1_T3 Average time 136.0\nTask E11_A2_T1 Average time 178.5\nTask E11_A2_T2 Average time 136.5\nTask E11_A2_T3 Average time 136.0\nTask E11_A2_T4 Average time 229.0\nTask E12_A1_T1 Average time 179.5\nTask E12_A1_T2 Average time 141.0\nTask E12_A1_T3 Average time 155.0\nTask E12_A1_T4 Average time 228.0\nTask E12_A1_T5 Average time 189.5\nTask E12_A1_T6 Average time 248.0\nTask E12_A1_T7 Average time 272.0\nTask E12_A2_T1 Average time 124.5\nTask E12_A2_T2 Average time 395.5\nTask E12_A2_T3 Average time 206.0\nTask E12_A3_T1 Average time 102.0\nTask E12_A3_T2 Average time 168.0\nTask E12_A3_T3 Average time 93.5\nTask E12_A3_T4 Average time 342.0\nTask E12_A3_T5 Average time 194.0\nTask E2_A1_T3 Average time 42.0\nTask E7_A2_T3 Average time 128.0\nTask E9_A2_T6 Average time 100.0\n\n\n\n## Analyzing data for episode 11\n\n# df for episode 11\nep_df = df_.loc[df_['task_heirarchy'].str.contains('E11'),:]\n\n\n# df for student Peetri kooli kasutaja 78\nep_78 = ep_df.loc[ep_df['student'] == 'Peetri kooli kasutaja 78',:]\n\n\nep_78.to_csv('ep_78.csv', index=False)\n\n\nep_78_skills = pd.read_csv('ep_78_with_skills.csv')\n\n\ndef score_to_num(x):\n    if x is None:\n        return -1\n    elif '/' in x:\n        f = x.split('/')[0]\n        s = x.split('/')[1]\n        return float(f)/float(s)\n    else:\n        return -1\n\ndf_['score_'] =  df_['score'].apply(score_to_num) \n\n\n\ndf_dummy = pd.get_dummies(df_['outcomes'])\n\n\nfinal_ = pd.concat([df_[['required','success','attempts','score_']],df_dummy],axis=1)\n\n\nfinal_\n\n\n\n\n\n\n\n\n\nrequired\nsuccess\nattempts\nscore_\naddition of algebraic fractions\nbridging from multiplication of common farctions\ndivision of algerbaic fractions\nexpanding and reducing algebraic fractions\nexpanding and reducing common fractions\nintro to addition of algebraic fractions\nintro to expanding and reducing algebraic fractions\nintro to multiplication of algebraic farctions\nmultiplication of algebraic fractions\nunderstanding algebraic fractions\nunderstanding common fractions\n\n\n\n\n0\nYes\nNo\n0\n-1.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1\nNo\nNo\n0\n-1.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n2\nYes\nNo\n0\n-1.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n3\nNo\nNo\n0\n-1.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n4\nNo\nNo\n0\n-1.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2543\nYes\nNo\n0\n-1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2544\nNo\nNo\n0\n-1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2545\nNo\nNo\n0\n-1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2546\nYes\nNo\n0\n-1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2547\nYes\nNo\n0\n-1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n2548 rows × 15 columns"
  }
]